wandb_version: 1

env_id:
  desc: null
  value: Skip-v0
learning_rate:
  desc: null
  value: 0.0001
initial_epsilon:
  desc: null
  value: 1.0
final_epsilon:
  desc: null
  value: 0.01
'epsilon_decay_steps:':
  desc: null
  value: 2000
gamma:
  desc: null
  value: 0.99
learning_starts:
  desc: null
  value: 100
seed:
  desc: null
  value: 984
algo:
  desc: null
  value: RCPO
_wandb:
  desc: null
  value:
    code_path: code/policy_constraint.py
    python_version: 3.10.0
    cli_version: 0.17.5
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1722344219
    t:
      1:
      - 1
      - 2
      - 3
      - 55
      2:
      - 1
      - 2
      - 3
      - 55
      3:
      - 7
      - 13
      - 16
      - 23
      - 35
      - 61
      4: 3.10.0
      5: 0.17.5
      8:
      - 3
      - 5
      13: windows-amd64
    m:
    - 1: global_step
    - 1: eval/missing train
      5: 1
      6:
      - 1
    - 1: eval/maximum
      5: 1
      6:
      - 1
    - 1: eval/objective
      5: 1
      6:
      - 1
    - 1: eval/travel time
      5: 1
      6:
      - 1
    - 1: eval/passenger_num
      5: 1
      6:
      - 1
    - 1: eval//reward
      5: 1
      6:
      - 1
    - 1: losses/critic_loss
      5: 1
      6:
      - 1
    - 1: losses/epsilon
      5: 1
      6:
      - 1
    - 1: losses/actor_loss
      5: 1
      6:
      - 1
